# Ollama 壓力測試工具

這是一個基於Flask + Bootstrap 5的Ollama模型壓力測試網頁應用，可以幫助您測試不同Ollama模型在您系統上的性能表現，並提供詳細的硬體資訊和測試結果分析。

## 功能特色

### 🔧 基礎功能
- **硬體資訊檢測**: 頁面載入時自動檢測並直接顯示CPU、記憶體、GPU、系統等硬體資訊
- **模型管理**: 自動獲取本機可用的Ollama模型列表
- **響應式設計**: 使用Bootstrap 5設計，支援各種螢幕尺寸
- **智能控制**: 測試期間自動禁用相關控制項，防止重複測試和配置修改

### 🧪 測試一 - 基礎壓力測試
- **並發測試**: 支援多線程並發測試，可自定義並發數和總請求數
- **即時進度**: 使用AJAX輪詢技術提供即時的測試進度更新
- **詳細統計**: 提供完整的測試統計資訊，包括回應時間、成功率等
- **圖表顯示**: 使用Plotly.js提供互動式測試結果圖表

### 🎯 測試二 - 多用戶並發測試 (NEW!)
- **多用戶模擬**: 模擬1-10個用戶同時使用不同提示詞查詢同一模型
- **TPM性能測試**: 計算每分鐘回傳的Token數量(TPM)，評估模型吞吐量
- **智能提示詞**: 內建50組常用詢問句，每個用戶隨機選擇不同提示詞
- **真實場景**: 更貼近實際多用戶使用環境的測試場景
- **實時監控**: 顯示當前TPM、活躍用戶數等實時統計
- **靈活配置**: 支援自定義用戶數量、查詢次數、並發限制等參數

## 系統需求

- Python 3.8+
- Ollama 服務器正在運行
- 支援的作業系統: Windows, Linux, macOS

## 安裝步驟

1. **克隆或下載專案**
   ```bash
   git clone <repository-url>
   cd llmstresstest
   ```

2. **安裝依賴**
   ```bash
   pip install -r requirements.txt
   ```

3. **確保Ollama服務器運行**
   ```bash
   ollama serve
   ```

4. **啟動應用**
   ```bash
   python app_simple.py
   ```

5. **開啟瀏覽器**
   訪問 `http://localhost:5001`

## 使用方法

### 1. 查看硬體資訊
- 頁面載入時會直接顯示系統硬體資訊
- 包括CPU、記憶體、GPU、系統、網路資訊等
- 可點擊「重新整理」按鈕動態更新資訊

### 2. 選擇測試類型
- 在測試配置區域，您會看到兩個Tab標籤
- **測試一 - 基礎壓力測試**: 傳統的並發壓力測試
- **測試二 - 多用戶並發測試**: 多用戶TPM性能測試
- 點擊不同的Tab可以切換測試類型

### 3. 測試一 - 基礎壓力測試
#### 配置測試參數
- **選擇模型**: 從下拉選單中選擇要測試的Ollama模型
- **並發請求數**: 設定同時進行的請求數量 (1-20)
- **總請求數**: 設定測試的總請求數量 (1-1000)
- **測試提示詞**: 輸入要測試的提示詞內容

#### 執行測試
- 點擊「開始測試」按鈕啟動測試
- 測試開始後，按鈕會立即變為「🔄 測試中...」並禁用，防止重複測試
- 同時所有表單控制項也會被禁用以防止修改配置
- 測試過程中會顯示即時進度和統計資訊
- 可隨時點擊「停止測試」按鈕中止測試
- 測試完成或停止後，所有控制項會自動恢復正常狀態

### 4. 測試二 - 多用戶並發測試
#### 配置測試參數
- **選擇模型**: 從下拉選單中選擇要測試的Ollama模型
- **模擬用戶數量**: 選擇1-10個模擬用戶（建議從2個開始）
- **每用戶查詢次數**: 設定每個用戶執行的查詢次數
- **最大並發限制**: 控制同時執行的查詢數量，避免系統過載
- **查詢間隔**: 設定查詢之間的時間間隔（秒）
- **提示詞來源**:
  - 使用內建50組隨機提示詞（推薦）
  - 使用自定義提示詞

#### 執行測試
- 點擊「開始多用戶測試」按鈕啟動測試
- 系統會為每個用戶分配不同的隨機提示詞
- 實時顯示測試進度、當前TPM、活躍用戶數
- 可隨時停止測試
- 測試完成後顯示詳細的TPM統計和性能分析

### 5. 查看結果
- 測試完成後會顯示詳細的統計結果和視覺化圖表
- **測試一**: 成功率、回應時間統計、每秒請求數
  - 📊 回應時間分布直方圖
  - 🥧 請求成功率餅圖
  - 📈 回應時間趨勢圖
  - 📦 回應時間統計箱線圖
- **測試二**: TPM統計、多用戶性能分析、Token吞吐量報告
  - 🚀 TPM (每分鐘Token數) 趨勢圖
  - 👥 各用戶查詢統計圖
  - ✅ 各用戶成功率比較圖
  - 🎯 響應時間 vs Token數量散點圖
- 圖表會根據測試類型自動切換顯示
- 所有操作都會記錄在即時日誌中

## 檔案結構

```
llmstresstest/
├── app_simple.py              # 主應用程式 (簡化版)
├── hardware_info.py           # 硬體資訊檢測模組
├── ollama_client.py           # Ollama API客戶端
├── stress_test_simple.py      # 壓力測試管理器 (簡化版)
├── requirements.txt           # Python依賴列表
├── templates/
│   └── index_simple.html      # 主頁面模板
├── static/
│   └── js/
│       └── app_simple.js      # 前端JavaScript
└── README.md                  # 說明文件
```

## API端點

### 基礎API
- `GET /` - 主頁面
- `GET /api/hardware` - 獲取硬體資訊
- `GET /api/models` - 獲取可用模型列表

### 測試一API
- `POST /api/start_test` - 開始基礎壓力測試
- `POST /api/stop_test` - 停止基礎壓力測試
- `GET /api/test_status/<test_id>` - 獲取測試狀態
- `GET /api/test_charts/<test_id>` - 獲取測試圖表數據

### 測試二API (NEW!)
- `POST /api/start_multi_user_test` - 開始多用戶並發測試
- `POST /api/stop_multi_user_test` - 停止多用戶測試
- `GET /api/multi_user_test_status/<test_id>` - 獲取多用戶測試狀態
- `GET /api/multi_user_test_charts/<test_id>` - 獲取多用戶測試圖表數據

## 測試結果說明

### 統計指標
- **總請求數**: 執行的總請求數量
- **成功請求數**: 成功完成的請求數量
- **失敗請求數**: 失敗的請求數量
- **成功率**: 成功請求的百分比
- **最小/最大回應時間**: 最快和最慢的回應時間
- **平均回應時間**: 所有成功請求的平均回應時間
- **中位數回應時間**: 回應時間的中位數
- **標準差**: 回應時間的標準差
- **每秒請求數**: 平均每秒處理的請求數量

## 故障排除

### 常見問題

1. **Ollama服務器連接失敗**
   - 確保Ollama服務器正在運行: `ollama serve`
   - 檢查服務器地址是否正確 (預設: http://localhost:11434)

2. **沒有可用模型**
   - 確保已下載Ollama模型: `ollama pull <model-name>`
   - 檢查模型列表: `ollama list`

3. **硬體資訊顯示錯誤**
   - 某些硬體資訊可能需要管理員權限
   - GPU資訊需要安裝相應的驅動程式

4. **測試執行緩慢**
   - 降低並發請求數
   - 選擇較小的模型進行測試
   - 檢查系統資源使用情況

5. **端口被佔用**
   - 如果5001端口被佔用，可以修改app_simple.py中的端口號
   - 或者停止佔用端口的其他應用程式

## 開發說明

### 技術棧
- **後端**: Flask, Python
- **前端**: Bootstrap 5, JavaScript
- **硬體檢測**: psutil, GPUtil
- **HTTP客戶端**: requests

### 擴展功能
- 可以添加更多的硬體資訊檢測
- 支援更多的測試參數配置
- 添加測試結果的圖表顯示
- 支援測試結果的匯出功能

## 授權

本專案採用MIT授權條款。

## 貢獻

歡迎提交Issue和Pull Request來改進這個專案。

## 聯絡資訊

如有問題或建議，請通過GitHub Issues聯絡。
