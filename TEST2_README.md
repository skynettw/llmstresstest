# 測試二 - 多用戶並發測試功能說明

## 功能概述

測試二是一個專門設計的多用戶並發測試功能，用於模擬真實環境中多個用戶同時使用不同提示詞查詢同一個Ollama模型的場景。主要目的是測試模型的TPM (Tokens Per Minute) 性能和並發處理能力。

## 核心特性

### 🎯 測試目標
- **TPM性能測試**: 計算每分鐘回傳的Token數量
- **並發能力評估**: 測試模型在多用戶同時查詢時的表現
- **真實場景模擬**: 每個用戶使用不同的提示詞，更貼近實際使用情況

### 📊 測試配置
- **用戶數量**: 1-10個模擬用戶（下拉式選單選擇）
- **查詢次數**: 每個用戶可執行的查詢次數（可自定義）
- **並發控制**: 最大並發限制，避免系統過載
- **查詢間隔**: 控制查詢頻率，模擬真實使用節奏

### 💬 提示詞系統
- **內建提示詞庫**: 50組精心準備的常用詢問句
  - 基礎問答類 (10組)
  - 技術解釋類 (10組)
  - 生活應用類 (10組)
  - 知識問答類 (10組)
  - 創意思考類 (10組)
- **隨機分配**: 每個用戶自動獲得不同的提示詞組合
- **自定義選項**: 支援使用者自定義提示詞集

## 使用方法

### 1. 基本配置
1. 選擇要測試的Ollama模型
2. 設定模擬用戶數量 (建議從2個用戶開始)
3. 設定每個用戶的查詢次數
4. 調整並發限制和查詢間隔

### 2. 提示詞設定
- **推薦**: 選擇「使用內建50組隨機提示詞」
- **進階**: 選擇「使用自定義提示詞」並輸入自己的提示詞

### 3. 監控選項
- **TPM監控**: 啟用每分鐘Token數量統計
- **詳細日誌**: 記錄詳細的測試過程

### 4. 執行測試
1. 點擊「開始多用戶測試」
2. 觀察實時進度和TPM統計
3. 等待測試完成並查看結果

## 測試結果

### 📈 統計指標
- **總查詢數**: 所有用戶執行的查詢總數
- **成功查詢數**: 成功完成的查詢數量
- **成功率**: 成功查詢的百分比
- **總Token數**: 所有成功查詢回傳的Token總數
- **平均TPM**: 平均每分鐘Token數量
- **峰值TPM**: 測試期間的最高TPM值
- **平均響應時間**: 所有查詢的平均響應時間

### 📊 實時監控
- 測試進度百分比
- 當前TPM值
- 活躍用戶數
- 即時日誌更新

## 技術實現

### 後端架構
- **多線程並發**: 使用ThreadPoolExecutor實現真正的並發查詢
- **任務隊列**: 管理所有查詢任務的執行順序
- **狀態追蹤**: 實時追蹤每個用戶的查詢狀態
- **TPM計算**: 基於時間窗口的Token統計算法

### 前端交互
- **AJAX輪詢**: 每2秒更新一次測試狀態
- **實時進度**: 動態更新進度條和統計信息
- **配置預覽**: 友好的配置預覽界面
- **錯誤處理**: 完善的錯誤提示和恢復機制

## API端點

### 啟動測試
```
POST /api/start_multi_user_test
```

### 查詢狀態
```
GET /api/multi_user_test_status/<test_id>
```

### 停止測試
```
POST /api/stop_multi_user_test
```

## 使用建議

### 🚀 初次使用
1. 選擇較小的模型（如llama3:8b）
2. 從2個用戶、每用戶3次查詢開始
3. 使用內建隨機提示詞
4. 觀察系統資源使用情況

### ⚡ 性能優化
1. 根據硬體配置調整並發限制
2. 適當設定查詢間隔避免過載
3. 監控GPU/CPU使用率
4. 逐步增加用戶數量測試極限

### 📋 測試場景
- **基準測試**: 單用戶 vs 多用戶性能對比
- **負載測試**: 逐步增加用戶數量找出性能瓶頸
- **穩定性測試**: 長時間運行測試系統穩定性
- **模型對比**: 不同模型在相同條件下的TPM表現

## 注意事項

### ⚠️ 系統要求
- 確保Ollama服務器正常運行
- 有足夠的系統資源（RAM/GPU）
- 穩定的網路連接

### 🔧 故障排除
- 如果查詢失敗，檢查模型是否正確載入
- 如果TPM為0，確認模型能正常回應
- 如果測試卡住，可能是並發數設定過高

### 💡 最佳實踐
- 測試前先用測試一驗證模型可用性
- 從小規模測試開始，逐步擴大
- 記錄不同配置下的測試結果
- 定期清理日誌避免界面過於擁擠

## 文件結構

```
├── multi_user_test_config.py      # 數據結構和配置
├── multi_user_stress_test.py      # 核心測試邏輯
├── templates/index.html            # 前端界面
├── static/js/app_simple.js        # JavaScript交互
├── app.py                          # Flask API端點
├── demo_multi_user_test.py         # 演示腳本
└── TEST2_README.md                 # 本說明文件
```

## 更新日誌

### v1.0.0 (2025-01-11)
- ✅ 實現多用戶並發測試核心功能
- ✅ 內建50組常用提示詞庫
- ✅ TPM計算和實時監控
- ✅ 友好的Web界面
- ✅ 完整的API支持
- ✅ 詳細的統計報告

## 測試二的多用戶模擬方式相關說明與分析

測試二（多用戶並發測試）主要通過以下方式模擬多用戶存取模型：

<augment_code_snippet path="multi_user_stress_test.py" mode="EXCERPT">
````python
def _execute_concurrent_queries(self, test_id: str, config: MultiUserTestConfig,
                              result: MultiUserTestResult, task_queue: queue.Queue,
                              total_tasks: int, ollama_client: OllamaClient):
    """執行並發查詢"""
````
</augment_code_snippet>

### 主要特點

- **獨立用戶會話**: 為每個模擬用戶創建獨立的會話和提示詞列表
- **多線程並發**: 使用 ThreadPoolExecutor實現真正的並發請求
- **信號量控制**: 使用並發限制控制最大同時查詢數
- **隨機提示詞分配**: 從50組內建提示詞中隨機分配，確保用戶間的多樣性
- **查詢間隔控制**: 可設定查詢間的等待時間，模擬真實使用節奏

## 實際情況適用性分析

### ✅ 優點（符合實際情況的方面）

- **真實的並發模型**: 使用多線程實現真正的並發請求，而非簡單的循環
- **多樣化的提示詞**: 不同用戶使用不同提示詞，符合實際使用場景
- **可控的並發限制**: 模擬真實環境中的資源限制
- **查詢間隔設定**: 模擬用戶思考和輸入的時間間隔
- **TPM計算**: 提供實際生產環境中關鍵的性能指標

### ⚠️ 可能的問題點

#### 1. 單一進程限制
- 所有模擬用戶在同一個Python進程中運行，共享相同的資源
- 實際環境中，用戶請求來自不同的客戶端和網絡環境

#### 2. 網絡延遲模擬不足
- 測試中所有請求都是本地發送，沒有模擬真實網絡的延遲和不穩定性
- 實際環境中，網絡延遲和丟包會顯著影響用戶體驗

#### 3. 用戶行為模式簡化
- 測試中的用戶行為模式相對簡單（固定間隔發送請求）
- 實際用戶行為更加複雜，包括突發請求、長時間閒置等

#### 4. 資源競爭不真實
- 測試工具和Ollama服務器可能在同一台機器上運行，資源競爭不符合實際部署
- 生產環境中通常有更複雜的資源分配和負載均衡機制

#### 5. 會話連續性缺失
- 測試中每個查詢是獨立的，沒有模擬真實用戶的連續對話
- 實際使用中，用戶通常進行多輪對話，模型需要維護上下文

## 改進建議

若要更接近實際情況，可考慮以下改進：

### 🔧 技術改進
1. **分布式測試**: 使用多台機器或容器模擬不同用戶，更真實地模擬網絡環境
2. **動態負載模式**: 實現更複雜的用戶行為模式，如高峰期突發請求
3. **會話模擬**: 支持多輪對話測試，評估模型在維護上下文時的性能
4. **網絡條件模擬**: 加入網絡延遲、丟包等模擬，測試系統在不穩定網絡下的表現
5. **長時間穩定性測試**: 延長測試時間，評估系統在長期運行下的穩定性和資源使用

## 總結

測試二提供了一個良好的多用戶並發測試框架，適合初步評估模型的性能，但對於完全模擬生產環境的真實負載還有一定差距。不過，對於大多數用戶來說，這種測試方法已經能提供有價值的性能指標和優化方向。